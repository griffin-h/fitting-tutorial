{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Model to Data\n",
    "Latino Initiative Program Python Hour, 2019 July 22\n",
    "\n",
    "By: Griffin Hosseinzadeh (griffin.hosseinzadeh@cfa.harvard.edu)\n",
    "\n",
    "A common problem in astrophysics (any science really) is that you have some data and you want to use it to constrain a theoretical model. In other words, what parameters can you plug into the model to make it match your observations?\n",
    "[Here's an example](https://ui.adsabs.harvard.edu/abs/2017ApJ...845L..11H/graphics) from one of my papers.\n",
    "\n",
    "This notebook explores several techniques for doing this fitting in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import emcee\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Your Model\n",
    "Write a function that takes some x-values and model parameters and returns y-values according to your model. Let's start with a linear model, $y = mx + b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, slope, intercept):\n",
    "    \"\"\"A linear model.\"\"\"\n",
    "    # complete\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Some Fake Data\n",
    "Normally we would have real astronomical data to use, but since I want to show you how this works, we are going to make up some data. Randomly choose some parameters (slope and intercept) for your model. Then evaluate the model over the range $x=0$ to $x=10$. Plot your fake data using `plt.plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_true = [ # pick some parameters\n",
    "x = np.arange( # complete\n",
    "y = # complete\n",
    "plt.plot( # complete\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title('Fake Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these were real data, they would not be so perfect. So let's add in some noise using the `np.random` module. Plot the noisy data using `plt.errorbar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc = # pick an uncertainty\n",
    "y_noisy = y + unc * np.random.standard_normal( # complete\n",
    "plt.errorbar( # complete\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title('Fake Data with Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, we are going to use `x` and `y_noisy` as our data. Each time we try to fit the data with our model, we will compare our results to the `p_true` that we used to generate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit a Polynomial Model with `np.polyfit`\n",
    "Since our model is a polynomial, the easiest thing we can use is `np.polyfit`. Look at the documentation for that function and use it to fit a 1st degree polynomial (a straight line) to our noisy data. Print the parameters you get, and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fit = np.polyfit( # complete\n",
    "y_fit = # complete\n",
    "plt.errorbar( # complete\n",
    "plt.plot( # complete\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "print(p_fit, p_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit a Linear Model with `scipy.optimize.curve_fit`.\n",
    "The next thing we can try is `scipy.optimize.curve_fit`. This function can fit _any_ model, as long as you can write it down as a function. Luckily we have already done this when we generated the data. Give `curve_fit` the model and the noisy data and see what parameters it comes up with. Compare these to `np.polyfit` and the true parameters. Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_curve_fit, cov_curve_fit = scipy.optimize.curve_fit( # complete\n",
    "y_curve_fit = # complete\n",
    "plt.errorbar( # complete\n",
    "plt.plot( # complete\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "print(p_curve_fit, p_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Redo All of the Above with a Non-Polynomial Model\n",
    "This all works great, but it's pretty easy to fit a line. (You could even do it without a computer if you were patient enough!) Let's see what happens if you use a model that is not a polynomial. You could try a sinusoid, an exponential, a power law, or any other function you can think of. Stick with 2 parameters for now. Once you do that, repeat Sections 2-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Use Markov-Chain Monte Carlo Regression\n",
    "We won't have time to do this today, but below is an example of using a more advanced Bayesian statistical technique to find the best fit parameters *with uncertainties* for any model function. For more details, try the tutorial at https://emcee.readthedocs.io/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the probability of a model being correct.\n",
    "# This is related to the residuals (how far the points are from the model).\n",
    "def log_posterior(p, x, y, unc):\n",
    "    \"\"\"Posterior probability distribution, assuming uniform priors.\"\"\"\n",
    "    if p[0] > 0. and 0. < p[1] < 2. * np.pi:\n",
    "        y_fit = model(x, p[0], p[1])\n",
    "        resid = y - y_fit\n",
    "        log_prob = np.sum(-resid**2. / (2. * unc**2.) - np.log(unc))\n",
    "    else:\n",
    "        log_prob = -np.inf\n",
    "    return log_prob\n",
    "\n",
    "# Make some initial guesses about what the parameters are.\n",
    "# In this case, I chose random numbers around 5 for both.\n",
    "initial_guesses = 0.1 * np.random.standard_normal(10, 2) + 5.\n",
    "\n",
    "# Set up the \"sampler\" object. This contains 10 \"walkers\" that are going to explore the parameter space.\n",
    "# They each \"walk\" for 100 steps and eventually end up at values near the true parameters.\n",
    "sampler = emcee.EnsembleSampler(10, 2, log_posterior, args=(x, y, unc))\n",
    "sampler.run_mcmc(initial_guesses, 100)\n",
    "\n",
    "# Plot the path each walker takes over its 100 steps.\n",
    "# You can see that they converge on values near the true value.\n",
    "plt.figure()\n",
    "plt.plot(sampler.chain[:, :, 0].T, lw=1)\n",
    "plt.xlabel('Step Number')\n",
    "plt.ylabel('Parameter 1')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sampler.chain[:, :, 1].T, lw=1)\n",
    "plt.xlabel('Step Number')\n",
    "plt.ylabel('Parameter 2')\n",
    "\n",
    "# For each pair of parameters, you can plot the model.\n",
    "# Notice how they all seem to fit equally well, given the noise.\n",
    "# Later you could take the mean/median and standard deviation of these parameters.\n",
    "p_emcee = sampler.chain[:, -1]\n",
    "plt.figure()\n",
    "plt.errorbar(x, y_noisy, unc, fmt='.')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "for p in p_emcee:\n",
    "    print(p)\n",
    "    y_emcee = model(x, p[0], p[1])\n",
    "    plt.plot(x, y_emcee, lw=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}